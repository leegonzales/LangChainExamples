{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/leegonzales/LangchainExamples/blob/main/LangChain_%3C%3E_Wolfram_Alpha.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_4XQa8P2QveN"
      },
      "outputs": [],
      "source": [
        "!pip install openai wolframalpha langchain==0.0.60"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
        "os.environ[\"WOLFRAM_ALPHA_APPID\"] = \"\""
      ],
      "metadata": {
        "id": "SrOmMIOEQ2BH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import load_tools, initialize_agent\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.chains.conversation.memory import ConversationBufferMemory"
      ],
      "metadata": {
        "id": "lsXopq3wSKCB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = OpenAI(temperature=0)\n",
        "tools = load_tools(['wolfram-alpha'])\n",
        "memory = ConversationBufferMemory(memory_key=\"chat_history\")\n",
        "agent = initialize_agent(tools, llm, agent=\"conversational-react-description\", memory=memory, verbose=True)"
      ],
      "metadata": {
        "id": "m7FFbXLYSP05"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent.run(\"Hi!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        },
        "id": "M4S2HDizS6L2",
        "outputId": "a5cff193-9f8f-4063-cda9-cefc4f0c5bb3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "Thought: Do I need to use a tool? No\n",
            "AI: Hi there! How can I help you?\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Hi there! How can I help you?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "agent.run(\"How far is it from Chicago to Tokyo\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "id": "qhb7jNzqSYLR",
        "outputId": "ae7d76ad-1125-41f5-8cca-9e52e17a0baf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "Thought: Do I need to use a tool? Yes\n",
            "Action: Wolfram Alpha\n",
            "Action Input: Distance from Chicago to Tokyo\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3m6313 miles\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m Do I need to use a tool? No\n",
            "AI: The distance from Chicago to Tokyo is 6313 miles.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The distance from Chicago to Tokyo is 6313 miles.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "agent.run(\"Is wolfram alpha better than gpt3?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "id": "I95lcrt_SuVO",
        "outputId": "5e6f4952-04d7-4cb9-9d26-77610be9ec78"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "Thought: Do I need to use a tool? No\n",
            "AI: It's hard to say which is better, as both Wolfram Alpha and GPT-3 have their own strengths and weaknesses. Wolfram Alpha is great for answering questions about Math, Science, Technology, Culture, Society and Everyday Life, while GPT-3 is better suited for generating human-like text and engaging in natural-sounding conversations.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"It's hard to say which is better, as both Wolfram Alpha and GPT-3 have their own strengths and weaknesses. Wolfram Alpha is great for answering questions about Math, Science, Technology, Culture, Society and Everyday Life, while GPT-3 is better suited for generating human-like text and engaging in natural-sounding conversations.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "agent.run(\"what do you think would happen if we combined them?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "id": "qMSSWy9JTTuO",
        "outputId": "879c5b85-9992-4c20-953d-cebbbee5a626"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "Thought: Do I need to use a tool? No\n",
            "AI: Combining Wolfram Alpha and GPT-3 could potentially create a powerful tool that could answer complex questions and generate human-like text. It could be used to provide in-depth explanations and discussions on a wide range of topics, and could be used to engage in natural-sounding conversations.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Combining Wolfram Alpha and GPT-3 could potentially create a powerful tool that could answer complex questions and generate human-like text. It could be used to provide in-depth explanations and discussions on a wide range of topics, and could be used to engage in natural-sounding conversations.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "go0q6VxcTiKS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}